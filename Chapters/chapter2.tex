\chapter{\selectlanguage{greek}Γραμμικοί Μπλoκ Κώδικες}\externaldocument{chapter1.tex}
Στο κεφάλαιο αυτό, παρουσιάζονται οι βασικές αλγεβρικές δομικές ιδιότητες που προσδίδονται στους κώδικες καναλιού, οι οποίες διακρίνουν και τους κώδικες πάνω στους οποίους στηρίζεται η παρούσα εργασία και που θα παρουσιαστούν στο επόμενο κεφάλαιο. Όπως αναφέρθηκε στο εισαγωγικό κεφάλαιο, το σώμα που υιοθετείται είναι το $\mathbb{F}_2$. Συνεπώς, θεωρείται πως η έξοδος της πηγής πληροφορίας είναι μια διακριτή ακολουθία \en{i.i.d.} δυαδικών ψηφίων, η οποία καλείται \textit{ακολουθία πληροφορίας}. Η μετάδοση λαμβάνει χώρα μέσω διακριτού καναλιού, όπως αυτό ορίστηκε στον Ορισμό \ref{def:discrete channel}. Υπενθυμίζεται ακόμη πως η έκφραση \enquote{κώδικας $C(n,M)$}, αναφέρεται στο κωδικό βιβλίο του κώδικα.

\section{Μπλοκ κώδικες}
Ξεκινώντας τη μελέτη των δομών που αναφέρθηκαν παραπάνω, ορίζεται η κλάση των κωδίκων καναλιού, οι κώδικες \textit{μπλοκ} (\en{block codes}).

Η αρχή λειτουργίας της μπλοκ κωδικοποίησης, συνίσταται στην κατάτμηση της ροής πληροφορίας σε σταθερά μπλοκ $\mathbf{u} = (u_0, u_1, ..., u_{k-1})$ μήκους $k$ και στην απεικόνισή της πριν την είσοδο του καναλιού, μέσω του κωδικοποιητή καναλιού, στην κωδική λέξη $\mathbf{v} = (v_0, v_1, ..., v_{n-1})$ μήκους $n$, με $n>k$. H απεικόνιση αυτή είναι ανεξάρτητη από τα προηγούμενα μπλοκ, δηλαδή δεν υπάρχει μνήμη από ένα μήνυμα, σε ένα άλλο επόμενο \cite{proakis1994communication}.

\begin{figure}[h]
\center{\includegraphics[width=0.75\linewidth]{figures/linear_block_codes.png}}
\caption{Σχηματικό διάγραμμα ενός μπλοκ κώδικα}
\label{fig:linear block codes}
\end{figure}

\subsection{Ρυθμός δυαδικού κώδικα}
Στο προηγούμενο κεφάλαιο ορίστηκε ο ρυθμός του κώδικα ως $R=\frac{\log_{2}M}{n}$. Επίσης ισχύει πως η πληθυκότητα (\en{cardinality}) του μπλοκ κώδικα $C$ στο $\mathbb{F}_2$, το σύνολο δηλαδή των δυνατών κωδικών λέξεων του κωδικού βιβλίου, είναι $M=2^k$. Εφαρμόζοντας τις παραπάνω σχέσεις, προκύπτει ο λόγος
\begin{equation}
R = \frac{\log_{2}2^{k}}{n} = \frac{k}{n}
\label{eq:code rate}
\end{equation}
ο οποίος καλείται \textit{ρυθμός} του μπλοκ κώδικα (\en{\textit{code rate}}) και αντιπροσωπεύει τον μέσο όρο πληροφορίας που αποστέλλεται με κάθε κωδικό \en{bit}, ανν τα \en{bits} πληροφορίας είναι ανεξάρτητα και ισοπίθανα (\en{i.u.d.}). Προφανώς ισχύει $0<R<1$.

\vspace{5mm}

Όπως αναφέρθηκε, ο κώδικας αντιστοιχίζει κάθε μήνυμα πληροφορίας $\mathbf{u}$, στην κωδικολέξη $\mathbf{v}$, μήκους $n$, με $n>k$. Tα $n-k$ επιπλέον \en{bits} που προστίθενται στο μήνυμα από τον κωδικοποιητή καναλιού καλούνται \textit{πλεονασματικά} (\en{redundant}) \en{bits}.

Τα πλεονασματικά \en{bits} δεν περιέχουν επιπλέον πληροφορία και ο σκοπός τους είναι να δώσουν δυνατότητες \textit{ανίχνευσης} και \textit{διόρθωσης} σφαλμάτων, που προκύπτουν κατά τη μετάδοση στο κανάλι, λόγω θορύβου ή/και παρεμβολών. Το πώς διαμορφώνονται αυτά τα πλεονασματικά \en{bits}, ώστε ο μπλοκ κώδικας να έχει ικανοποιητικές δυνατότητες ανίχνευσης ή/και διόρθωσης, αποτελεί μείζων ζήτημα της σχεδίασης μηχανισμών κωδικοποίησης \cite{ryan2009channel}.

\section{Γραμμικοί μπλοκ κώδικες}
Eπιπρόσθετα από την δόμηση σε κωδικά \en{blocks}, είναι αναγκαίο να προσδώσουμε δομικές ιδιότητες στον κώδικα $C(n,M)$, ώστε οι παραπάνω διαδικασίες να καταστούν πρακτικά υλοποιήσιμες. Μια τέτοια δομική ιδιότητα είναι η \textit{γραμμικότητα}.

\vspace{5mm}

\begin{definition}
Ένας δυαδικός κώδικας μήκους $n$ καλείται $(n,k)$ \textit{γραμμικός μπλοκ κώδικας}, ανν οι $2^k$ κωδικές του λέξεις σχηματίζουν έναν $k$-διάστατο υποχώρο του διανυσματικού χώρου $V$ όλων των δυνατών $n$-άδων στο $\mathbb{F}_2$ \cite{ryan2009channel}.
\label{def:linear block code}
\end{definition}

Ένας ισοδύναμος ορισμός είναι ο εξής:

\begin{definition}
Ένας κώδικας μπλοκ είναι γραμμικός αν κάθε γραμμικός συνδυασμός δύο κωδικών του λέξεων, είναι επίσης κωδική του λέξη. Στο $\mathbb{F}_2$, αν $\mathbf{c_i}$ και $\mathbf{c_j}$ οι δύο κωδικές λέξεις, τότε πρέπει $\mathbf{c_i}\oplus\mathbf{c_j}$ να είναι επίσης κωδική λέξη του $C$, όπου με $\oplus$ συμβολίζεται η συνιστώσα-προς-συνιστώσα \en{modulo-2} πρόσθεση \cite{proakis1994communication}.
\end{definition}

Η ακολουθία \textbf{0} αποτελεί κωδική λέξη κάθε γραμμικού \en{block} κώδικα, αφού μπορεί να προκύψει ως συνιστώσα-προς-συνιστώσα \en{modulo-2} πρόσθεση μιας κωδικής λέξης με τον εαυτό της. Ακόμη φαίνεται πως η γραμμικότητα ενός κώδικα εξαρτάται αποκλειστικά από τις κωδικές του λέξεις και όχι από τον τρόπο με τον οποίο η ακολουθία πληροφορίας απεικονίζεται σε αυτές.

\section{Αναπαράσταση με πίνακα}

\subsection{Γεννήτορας πίνακας, \en{G}}
Σύμφωνα με τον ορισμό του γραμμικού μπλοκ κώδικα $C(n,k)$, αποδεικνύεται πως υπάρχουν $k$ γραμμικά ανεξάρτητες κωδικές λέξεις, $\mathbf{g_0, g_1, ..., g_{k-1}}$, έτσι ώστε κάθε κωδική λέξη $\mathbf{v}$ να προκύπτει ως γραμμικός συνδυασμός τους. Οι $k$ γραμμικά ανεξάρτητες αυτές κωδικές λέξεις λέγεται ότι σχηματίζουν μια \textit{βάση} του $C$.

Με βάση αυτό, η κωδική λέξη προκύπτει ως εξής: έστω $\mathbf{u} = (u_0, u_1, ..., u_{k-1})$ το μήνυμα στην είσοδο του κωδικοποιητή. Η κωδικολέξη $\mathbf{v} = (v_0, v_1, ..., v_{n-1})$ δίνεται από τον γραμμικό συνδυασμό των $\mathbf{g_0, g_1, ..., g_{k-1}}$ με συντελεστές τα $k$ \en{bits} πληροφορίας, από την παρακάτω εξίσωση:

\begin{equation}
\mathbf{v}=u_0\mathbf{g_0}+u_1\mathbf{g_1}+...+u_{k-1}\mathbf{g_{k-1}}
\label{eq:codeword formation}
\end{equation}

Οι συνιστώσες των $k$ γραμμικά ανεξάρτητων κωδικολέξεων μπορούν να αναπαρασταθούν ως γραμμές ενός $k\times n$ πίνακα στο $\mathbb{F}_2$ ως εξής:

\begin{equation}
\mathbf{G}=\begin{bmatrix}\mathbf{g_0}\\\mathbf{g_1}\\\vdots\\\mathbf{g_{k-1}}\\\end{bmatrix}=\begin{bmatrix}g_{0,0} & g_{0,1} & \cdots & g_{0,n-1}\\g_{1,0} & g_{1,1} & \cdots & g_{1,n-1}\\\vdots & \vdots & \ddots & \vdots\\g_{k-1,0} & g_{k-1,1} & \cdots & g_{k-1,n-1}\\\end{bmatrix}
\label{eq:generator matrix}
\end{equation}

Σε αυτή την περίπτωση, η κωδικολέξη $\mathbf{v}$ που αντιστοιχεί στο μήνυμα $\mathbf{u}$, δίνεται από τον πολλαπλασιασμό πινάκων: 

\begin{equation}
\mathbf{v=u \cdot G}
\label{eq:check equation}
\end{equation}

Ο πίνακας \en{\textbf{G}} καλείται \textit{πίνακας γεννήτορας} \en{(generator matrix)} του $(n,k)$ γραμμικού μπλοκ κώδικα $C$. Γενικά, ένας γραμμικός μπλοκ κώδικας δεν έχει μοναδική βάση. Συνεπώς κάθε επιλογή βάσης του $C$ δίνει διαφορετικό γεννήτορα πίνακα, οπότε προκύπτει πως ο πίνακας \en{\textbf{G}} δεν είναι μοναδικός για δεδομένο κώδικα. Ο βαθμός (\en{rank}) του πίνακα \en{\textbf{G}} είναι προφανώς ίσος με τη διάσταση του κώδικα $C$.

Παρατηρείται συνεπώς, πως μειώνεται σημαντικά η πολυπλοκότητα περιγραφής του κώδικα, αφού πλέον αρκεί ο κωδικοποιητής να αποθηκεύσει τις $k$ γραμμές του πίνακα \en{\textbf{G}}. Επιπρόσθετα, η εκτέλεση του πολλαπλασιασμού πινάκων που περιγράφει η \ref{eq:check equation} απαιτεί περίπου $2kn$ πράξεις, δηλαδή είναι τετραγωνικής πολυπλοκότητας ως προς το $n$ - $\mathcal{O}(n^2)$.

\subsection{Πίνακας ελέγχου ισοτιμίας, \en{H}}
\begin{definition}
Ο δυικός κώδικας (\en{\textit{dual code}}) του $C$, $C_d$ δίνεται από τις παρακάτω $n$-άδες:$$C_d=\lbrace\mathbf{w}\in V:\langle \mathbf{w,v} \rangle =0\;\;\;\forall\;\mathbf{v}\in C\rbrace$$,
όπου με $\langle\cdot,\cdot\rangle$ συμβολίζεται το διανυσματικό εσωτερικό γινόμενο \cite{ryan2009channel}.
\label{def:dual code}
\end{definition}

Από τον Ορισμό \ref{def:dual code} προκύπτουν τα παρακάτω:

\begin{itemize}
\item Αν η βάση του $C$ αποτελείται από $k$ γραμμικά ανεξάρτητες κωδικές λέξεις, η βάση του $C_d$ αποτελείται από ($n-k$) γραμμικά ανεξάρτητες $n$-άδες.
\item Έστω $\mathbf{h_0, h_1, ..., h_{n-k-1}}$ οι ($n-k$) αυτές, γραμμικά ανεξάρτητες $n$-άδες. Συνεπάγεται πως κάθε $n$-άδα στον $C_d$ προκύπτει ως γραμμικός συνδυασμός τους
\item Ομοίως με τον πίνακα \en{\textbf{G}}, οι παραπάνω γραμμικά ανεξάρτητες $n$-άδες μπορούν να αναπαρασταθούν ως γραμμές ενός πίνακα στο $\mathbb{F}_2$, που σχηματίζεται ως εξής:

\begin{equation}
\mathbf{H}=\begin{bmatrix}\mathbf{h_0}\\\mathbf{h_1}\\\vdots\\\mathbf{h_{n-k-1}}\\\end{bmatrix}=\begin{bmatrix}h_{0,0} & h_{0,1} & \cdots & h_{0,n-1}\\h_{1,0} & h_{1,1} & \cdots & h_{1,n-1}\\\vdots & \vdots & \ddots & \vdots\\h_{n-k-1,0} & h_{n-k-1,1} & \cdots & h_{n-k-1,n-1}\\\end{bmatrix}
\label{eq:parity check matrix}
\end{equation}
\item Ο πίνακας $\mathbf{H}$ είναι γεννήτορας πίνακας του $C_d$, ακριβώς όπως ο $\mathbf{G}$ είναι του $C$. Λόγω αυτού και από την ιδιότητα της ορθογωνιότητας, προκύπτει η πολύ χρήσιμη εξίσωση $\mathbf{G} \cdot \mathbf{H^T} = \mathbf{0}$, όπου $\mathbf{0}$ μηδενικός $k \times (n-k)$ πίνακας.
\end{itemize}

Ακόμη, προκύπτει πως ο κώδικας $C$ ορίζεται με μοναδικό τρόπο από τον πίνακα $\mathbf{H}$, επειδή κάθε δυαδική $n$-άδα $\mathbf{v}$ είναι κωδικολέξη του $C$ ανν
ισχύει $\mathbf{v} \cdot \mathbf{H^T} = \mathbf{0}$, δηλαδή
\begin{equation}
C=\lbrace\mathbf{v}\in V:\mathbf{v} \cdot \mathbf{H^T} = \mathbf{0}\rbrace
\label{eq:decoding equation}
\end{equation}

Ο πίνακας $\mathbf{H}$ καλείται πίνακας \textit{ελέγχου ισοτιμίας} (\en{parity check matrix}) του κώδικα $C$. Από την παραπάνω σχέση ορισμού ενός γραμμικού κώδικα (εξίσωση \ref{eq:decoding equation}), προέρχεται και το όνομα του $\mathbf{H}$, αφού, στην πλευρά του αποκωδικοποιητή, ο $\mathbf{H}$ χρησιμοποιείται για την επαλήθευση του παραπάνω συστήματος ομογενών εξισώσεων, όταν το διάνυσμα $\mathbf{v}$, αντικατασταθεί με το ληφθέν διάνυσμα.

Παρατηρείται επομένως, πως ο γραμμικός μπλοκ κώδικας $C$ μπορεί να οριστεί πλήρως από δύο πίνακες, τον γεννήτορα ή τον πίνακα ελέγχου ισοτιμίας. Στη γενική περίπτωση, η κωδικοποίηση του $C$ βασίζεται στον γεννήτορα πίνακα και ακολουθεί την εξίσωση \ref{eq:check equation}, ενώ η αποκωδικοποίηση βασίζεται στον πίνακα ελέγχου ισοτιμίας.

Ο πίνακας ελέγχου ισοτιμίας μπορεί να περιγράψει πλήρως έναν κώδικα, και ορισμένες κατηγορίες γραμμικών μπλοκ κωδίκων κατασκευάζονται με βάση τον πίνακα $\mathbf{H}$. Ο πίνακας $\mathbf{H}$ είναι \textit{πλήρους βαθμού} (\en{full rank}), ανν ο βαθμός του είναι ίσος με το πλήθος των σειρών. Σε πολλές περιπτώσεις, ο πίνακας $\mathbf{H}$ δεν δίνεται σε \en{full rank} μορφή, δηλαδή το πλήθος των σειρών του είναι μεγαλύτερο από το \en{rank} του, $n-k$, ή ισοδύναμα, ορισμένες από τις σειρές του είναι γραμμικός συνδυασμός των $n-k$ γραμμικά ανεξάρτητων σειρών. Οι σειρές αυτές ονομάζονται \textit{πλεονάζουσες} (\en{redundant}) σειρές. 

Οι κώδικες Ελέγχου Ισοτιμίας Χαμηλής Πυκνότητας (\en{Low Density Parity Check - LDPC}), που θα εξεταστούν στη συνέχεια της εργασίας, διακρίνονται από πίνακες $\mathbf{H}$ που δεν είναι \en{full rank} \cite{cover2012elements}, \cite{ryan2009channel}.

\section{Κώδικες σε συστηματική μορφή}

\begin{figure}[h]
\center{\includegraphics[width=0.65\linewidth]{figures/systematic_form.png}}
\caption{Κωδική λέξη σε συστηματική μορφή}
\label{fig:systematic form}
\end{figure}

Μία ακόμη επιθυμητή ιδιότητα, είναι οι κωδικές λέξεις ενός γραμμικού μπλοκ κώδικα $C(n,k)$ να έχουν τη μορφή που φαίνεται στο Σχήμα \ref{fig:systematic form}, η οποία καλείται \textit{συστηματική μορφή} (\en{systematic form}). Στη συστηματική μορφή, η κωδική λέξη χωρίζεται στο τμήμα μηνύματος (\en{data part}) και στο πλεονάζον τμήμα ελέγχου (\en{parity part}). Το τμήμα μηνύματος αποτελείται από τα $k$ αναλλοίωτα ψηφία πληροφορίας και το πλεονάζον τμήμα ελέγχου, από τα $n-k$ \en{bits} ελέγχου ισοτιμίας. Ολόκληρος ο γραμμικός \en{block} κώδικας $C(n,k)$ βρίσκεται σε \textit{συστηματική} μορφή, όταν όλα τα στοιχεία του κωδικού βιβλίου βρίσκονται σε συστηματική μορφή, ή ισοδύναμα, όταν μπορεί να οριστεί πλήρως από έναν $k \times n$ γεννήτορα πίνακα με την παρακάτω μορφή:

\begin{equation}
\mathbf{G} = \left[\mathbf{P}\;\;\mathbf{I}_{k}\right]= 
\left[\underbrace{\begin{matrix}
p_{0,0} & p_{0,1} & \cdots & p_{0,n-k-1} \\
p_{1,0} & p_{1,1} & \cdots & p_{1,n-k-1} \\
\vdots & \vdots & \ddots & \vdots \\
p_{k-1,0} & p_{k-1,1} & \cdots & p_{k-1,n-k-1}
\end{matrix}}_{\text{\en{\textbf{P}} πίνακας}}\;
\underbrace{\begin{matrix}
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1
\end{matrix}}_{\text{$k\times k$ $\mathbf{I}_k$ μοναδιαίος πίνακας}}\right]
\label{eq:generator matrix systematic form}
\end{equation}

\vspace{5mm}

Όπως διαπιστώνεται και από την εξίσωση \ref{eq:generator matrix systematic form}, ο γεννήτορας πίνακας $\mathbf{G}$, που για συντομία σημειώνεται ως $\mathbf{G}=\left[\mathbf{P}\;\;\mathbf{I}_k\right]$, αποτελείται από δύο υποπίνακες, έναν $k\times (n-k)$ υποπίνακα $\mathbf{P}$ στα αριστερά, ο οποίος καλείται υποπίνακας ελέγχου ισοτιμίας του $\mathbf{G}$ και έναν $k\times k$ μοναδιαίο πίνακα $\mathbf{I}_k$ στα δεξιά \cite{ryan2009channel}.

Η συστηματική μορφή του πίνακα $\mathbf{G}$ έχει σημαντικά πλεονεκτήματα καθώς σε κάθε κωδική λέξη, τα \en{bits} πληροφορίας παραμένουν αναλλοίωτα στις τελευταίες $k$ θέσεις της. Μειώνεται συνεπώς η πολυπλοκότητα κωδικοποίησης, αφού χρειάζεται να υπολογιστούν μόνο τα σύμβολα στις θέσεις του πλεονάζοντος τμήματος ελέγχου.

Αντίστοιχα, η συστηματική μορφή του πίνακα ελέγχου ισοτιμίας διαμορφώνεται ως εξής:

\begin{equation}
\mathbf{H}=\left[\mathbf{I}_{n-k}\;\;\mathbf{P^T}\right]
=\begin{bmatrix}
1 & 0 & \cdots & 0 & \; & p_{0,0} & p_{1,0} & \cdots & p_{k-1,0} \\
0 & 1 & \cdots & 0 & \; & p_{0,1} & p_{1,1} & \cdots & p_{k-1,1} \\
\vdots & \vdots & \ddots & \vdots  & \; & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1 & \; & p_{0,n-k-1} & p_{1,n-k-1} & \cdots & p_{k-1,n-k-1}
\end{bmatrix}
\label{eq:parity check matrix systematic form}
\end{equation}

\vspace{5mm}
Προφανώς ισχύει και πάλι ότι $\mathbf{G}\cdot\mathbf{H^T}=\mathbf{0}$.

Θεωρείται και πάλι το μήνυμα πληροφορίας $\mathbf{u} = (u_0, u_1, ..., u_{k-1})$. Αν εφαρμοστεί η εξίσωση \ref{eq:check equation}, όταν ο πίνακας $\mathbf{G}$ είναι σε συστηματική μορφή, η κωδική λέξη προκύπτει από τον παρακάτω πολλαπλασιασμό:

\begin{equation}
\begin{split}
\mathbf{v} & = \left( u_0, u_1, \cdots, u_{k-1} \right) \cdot \mathbf{G}\\
& = \left( v_0, v_1, \cdots, v_{n-k-1}, v_{n-k}, \cdots, v_{n-1} \right)
\end{split}
\label{eq:systematic codeword formation}
\end{equation}

\vspace{5mm}

τα $n$ στοιχεία της οποίας προκύπτουν ως εξής:

\begin{equation}
\begin{aligned}
v_{n-k+i}=u_i\;\;\ & \forall\;\;0\leq i \leq k-1  \\
v_j=u_0p_{0,j}+u_1p_{1,j}+\cdots+u_{k-1}p_{k-1,j}\;\; & \forall\;\;0\leq j \leq n-k-1
\end{aligned}
\label{eq:systematic codeword bits}
\end{equation}

\vspace{5mm}

Οι εξισώσεις \ref{eq:systematic codeword bits} δείχνουν πως τα δεξιότερα $k$ \en{bits} της κωδικής λέξης παραμένουν αναλλοίωτα τα $k$ \en{bits} του μηνύματος πληροφορίας και τα υπόλοιπα $n-k$ αποτελούν γραμμικό συνδυασμό των \en{bits} πληροφορίας και ορίζονται πλήρως από τις $n-k$ στήλες του υποπίνακα $\mathbf{P}$, όπως αυτός ορίζεται στην εξίσωση \ref{eq:generator matrix systematic form}. Η δεύτερη έκφραση, αποτελεί ένα σύστημα $n-k$ εξισώσεων οι οποίες ονομάζονται εξισώσεις ελέγχου ισοτιμίας.

Η συστηματική μορφή προσφέρει το πλεονέκτημα λιγότερων υπολογισμών κατά την κωδικοποίηση, καθώς το μήνυμα πληροφορίας παραμένει ατόφιο και 
απαιτείται υπολογισμός μόνο των \en{bits} του τμήματος ελέγχου, κάτι που οδηγεί σε μειωμένη πολυπλοκότητα περιγραφής. Ακόμη, προσφέρει ένα επιπλέον πλεονέκτημα κατά την αποκωδικοποίηση, μιας και αφού αποφασιστεί ποια είναι η αποσταλείσα κωδική λέξη, εξάγεται άμεσα το μήνυμα.

\section{Κατανομή Βαρών - Ελάχιστη Απόσταση \en{Hamming}}

Παρακάτω θα δοθούν οι ορισμοί μερικών βασικών παραμέτρων ενός κώδικα. Οι έννοιες που θα οριστούν, βοηθούν στην κατανόηση της δυνατότητας εντοπισμού και διόρθωσης σφαλμάτων των γραμμικών μπλοκ κωδίκων που θα συζητηθεί στη συνέχεια.

\begin{definition}Απόσταση \en{Hamming}

Έστω δύο $n$-άδες, $\mathbf{v}$ και $\mathbf{w}$. Η απόσταση \en{Hamming} ορίζεται ως ο αριθμός των συνιστωσών στις οποίες διαφέρουν μεταξύ τους και συμβολίζεται με $d\left(\mathbf{v},\mathbf{w}\right)$.
\label{def:Hamming distance}
\end{definition}

\begin{definition}Βάρος \en{Hamming}

Το βάρος \en{Hamming} μιας $n$-άδας, $\mathbf{v}$ ορίζεται ως το πλήθος των μη μηδενικών στοιχείων της και συμβολίζεται με $w\left(\mathbf{v}\right)$
\label{def:Hamming weight}
\end{definition}

Από τους ορισμούς \ref{def:Hamming distance}, \ref{def:Hamming weight} προκύπτει πως η απόσταση \en{Hamming} μεταξύ δύο $n$-άδων ισούται με το βάρος του αθροίσματός τους \en{modulo}-2, δηλ $d\left(\mathbf{v},\mathbf{w}\right) = w\left(\mathbf{v}+\mathbf{w}\right)$.

\begin{definition}
Η ελάχιστη απόσταση ενός κώδικα ορίζεται ως η ελάχιστη απόσταση \en{Hamming} μεταξύ δύο διαφορετικών κωδικών λέξεων, δηλαδή
\begin{equation}
d_{min} = \min_{\mathbf{v}, \mathbf{w}}d\left(\mathbf{v}, \mathbf{w}\right)
\label{eq:min distance}
\end{equation}
\end{definition}

\begin{definition}
Το ελάχιστο βάρος ενός κώδικα, ορίζεται από την παρακάτω σχέση
\begin{equation}
w_{min} = \min_{\mathbf{v}\neq\mathbf{0}}w\left(\mathbf{v}\right)
\label{eq:min weight}
\end{equation}
είναι δηλαδή, το ελάχιστο των βαρών των κωδικών λέξεων του κώδικα, αν εξαιρεθεί η μηδενική κωδική λέξη.
\end{definition}

Από τα παραπάνω, καθώς και από την ιδιότητα της γραμμικότητας, προκύπτει το παρακάτω θεώρημα:

\begin{theorem}
Η ελάχιστη απόσταση ενός γραμμικού κώδικα είναι ίση με το ελάχιστο βάρος του. Η απόδειξη του θεωρήματος είναι η ακόλουθη:
\begin{equation}
\begin{split}
d_{min}(C) & = \min \lbrace d \left( \mathbf{v},\mathbf{w} \right) : \mathbf{v},\mathbf{w} \in C, \mathbf{v}\neq\mathbf{w} \rbrace \\
& = \min \lbrace w \left( \mathbf{v}+\mathbf{w} \right) : \mathbf{v},\mathbf{w} \in C, \mathbf{v}\neq\mathbf{w} \rbrace \\
& = \min \lbrace w \left( \mathbf{x} \right) : \mathbf{x} \in C, \mathbf{x}\neq\mathbf{0} \rbrace \\
& = w_{min}(C).
\end{split}
\end{equation}
\label{theorem:min distance}
\end{theorem}

\vspace{3mm}
Μπορεί πλέον να οριστεί και η \textit{κατανομή βάρους} του κώδικα $C$. Έστω $A_i$ ο αριθμός των κωδικών λέξεων του $C(n,k)$ με βάρος \en{Hamming} $i$. Η κατανομή βάρους του $C$ αποτελείται από τους αριθμούς $A_0,A_1,\cdots,A_n$ για $0\leq i \leq n$. Ισχύουν οι παρακάτω σχέσεις:

\begin{equation}
\begin{aligned}
A_0+A_1+\cdots+A_n& = 2^k \\ 
Α_0 & =  1
\end{aligned}
\end{equation}

Η κατανομή βάρους ενός κώδικα αποτελεί σημαντικό εργαλείο στον καθορισμό της πιθανότητας να συμβεί ένα μη-ανιχνεύσιμο σφάλμα κατά την αποκωδικοποίηση καθώς αποτελεί παράγοντα του άνω ορίου της πιθανότητας αυτής. Δίνει επίσης την εικόνα της κατανομής αποστάσεων μεταξύ των κωδικών λέξεων ενός κώδικα, σε σχέση με την κωδική λέξη $\mathbf{0}$, καθώς το $A_i$ αποτελεί και τον αριθμό των κωδικών λέξεων που απέχουν από τη μηδενική κωδικολέξη, απόσταση $i$ \cite{ryan2009channel}, \cite{macwilliams1977theory}, \cite{peterson1972error}.

\section{Ανίχνευση σφαλμάτων - Αποκωδικοποίηση - Πολυπλοκότητα}

Έστω ένας γραμμικός μπλοκ κώδικας $C(n,k)$, που ορίζεται από τον πίνακα ελέγχου ισοτιμίας $\mathbf{H}$ και $\mathbf{v}=\left(v_0, v_1,\cdots,v_{n-1}\right)$, $\mathbf{r}=\left(r_0, r_1,\cdots,r_{n-1}\right)$ η κωδική λέξη στην είσοδο του καναλιού και το λαμβανόμενο σήμα στο δέκτη αντίστοιχα.

Το διάνυσμα $$\mathbf{e}=\mathbf{r}+\mathbf{v}$$, όπου $e_i=r_i+v_i,\;0\leq j\leq n-1$ και η πρόσθεση είναι \en{modulo}-2, περιέχει 1 στις θέσεις στις οποίες η κωδικολέξη και το λαμβανόμενο διάνυσμα διαφέρουν. Συνεπώς, δίνει μια εικόνα των σφαλμάτων που υφίσταται η κωδική λέξη κατά τη διέλευσή της από το διακριτό κανάλι και καλείται πρότυπο σφάλματος (\en{error pattern}).

\begin{figure}[h]
\center{\includegraphics[width=0.3\linewidth]{figures/BSC.png}}
\caption{Το δυαδικό συμμετρικό κανάλι}
\label{fig:BSC channel}
\end{figure}

Αν υποθέσουμε πως το κανάλι είναι \textit{δυαδικό συμμετρικό} (\en{Binary Symmetric Channel - BSC}) κανάλι όπως στο Σχήμα \ref{fig:BSC channel}, η πιθανότητα να συμβεί σφάλμα σε οποιαδήποτε από τις $n$ θέσεις είναι η ίδια - $p$. Υπάρχουν $2^n-1$ διαφορετικά μη-μηδενικά πρότυπα σφάλματος. 

Για την ανίχνευση σφαλμάτων, ο αποκωδικοποιητής υπολογίζει τις παρακάτω $(n-k)$-άδες στο $\mathbb{F}_2$:

\begin{equation}
\mathbf{s} = \left(s_0, s_1, \cdots, s_{n-k-1}\right) = \mathbf{r}\cdot\mathbf{H^T}
\label{eq:syndrome formation}
\end{equation}

Το διάνυσμα $\mathbf{s}$ καλείται \textit{σύνδρομο} του $\mathbf{r}$ \cite{ryan2009channel}. Σύμφωνα με την εξίσωση \ref{eq:syndrome formation} και όσα έχουν ήδη αναφερθεί, το ληφθέν διάνυσμα θα είναι κωδικολέξη του $C$ ανν $\mathbf{s}=0$. Σε αντίθετη περίπτωση το ληφθέν διάνυσμα δεν είναι κωδική λέξη και σίγουρα περιέχει \textit{σφάλματα μετάδοσης}.

Στην περίπτωση που ισχύει $\mathbf{s}=0$, ο αποκωδικοποιητής θεωρεί το ληφθέν διάνυσμα κωδικολέξη του $C$ χωρίς σφάλματα. Ωστόσο, στην περίπτωση που το $\mathbf{r}$ ανήκει στο κωδικό βιβλίο του $C$ αλλά διαφέρει από την κωδική λέξη που στάλθηκε $\mathbf{v}$, ο αποκωδικοποιητής διαπράττει \textit{σφάλμα αποκωδικοποίησης}. Αυτό συμβαίνει στην περίπτωση που το πρότυπο σφάλματος $\mathbf{e}$ ταυτίζεται με μία κωδική λέξη και καλείται \textit{μη-ανιχνεύσιμο} πρότυπο σφάλματος. Υπάρχουν $2^k-1$ μη-ανιχνεύσιμα πρότυπα σφάλματος \cite{macwilliams1977theory}.

\subsection{Αποκωδικοποίηση}

Ένας από τους σκοπούς της χρήσης κωδικοποίησης είναι η αύξηση της Ευκλείδειας απόστασης μεταξύ των μεταδιδόμενων σημάτων και κατά συνέπεια, η μείωση της πιθανότητας σφάλματος για δεδομένη ισχύ εκπομπής. Για σηματοδοσία \en{BPSK} ή \en{QPSK} με απεικόνιση \en{Gray}, αυτό ισοδυναμεί με την απαίτηση η απόσταση \en{Hamming} μεταξύ των κωδικών λέξεων να είναι η μεγαλύτερη δυνατή. Καθώς ο υπολογισμός της απόστασης \en{Hamming} μεταξύ κάθε κωδικολέξης είναι πρακτικά αδύνατη διαδικασία, η σύγκριση της επίδοσης κωδίκων γίνεται με βάση την ελάχιστη απόσταση $d_{min}$ (ή με βάση το ελάχιστο βάρος $w_{min}$). Συνεπάγεται πως κώδικες με μεγαλύτερη $d_{min}$ έχουν συνήθως καλύτερες επιδόσεις \cite{proakis1994communication}.

Θεωρείται ο $C(n,k)$ γραμμικός \en{block} κώδικας με πίνακα ελέγχου ισοτιμίας $\mathbf{H}$, ελάχιστη απόσταση $d_{min}(C)$ και το ληφθέν διάνυσμα στο δέκτη, $\mathbf{r}$. Επιγραμματικά αναφέρεται πως, για αποκωδικοποίηση \textit{μέγιστης πιθανοφάνειας} (\en{maximum-likelihood decoding - MLD}), η απόφαση για τη μεταδιδόμενη κωδικολέξη λαμβάνεται με βάση τη μεγιστοποίηση της υπο-συνθήκη πιθανότητας $P(\mathbf{r}\mid\mathbf{v})$. Για το κανάλι \en{BSC} του Σχήματος \ref{fig:BSC channel}, αυτό ισοδυναμεί με τον υπολογισμό της απόστασης μεταξύ του $\mathbf{r}$ και κάθε κωδικής λέξης $\mathbf{v}$ και την επιλογή της κωδικής λέξης που ελαχιστοποιεί την απόσταση αυτή. Αυτός ο τρόπος αποκωδικοποίησης ονομάζεται \textit{κοντινότερου γείτονα} (\en{nearest-neighbor}) και αποτελεί αποκωδικοποίηση πλήρους \textit{διόρθωσης σφαλμάτων} (\en{complete error-correction}).

Η συγκεκριμένη μέθοδος αποκωδικοποίησης απαιτεί $2^k$ υπολογισμούς της απόστασης \en{Hamming}. Συνεπώς είναι αδύνατον να υλοποιηθεί πρακτικά για μεγάλα μήκη κώδικα. Στη συνέχεια θα δειχθούν μέθοδοι, για να πετύχουν εφάμιλλες επιδόσεις και ραγδαία μείωση της πολυπλοκότητας \cite{ryan2009channel}.

\subsection{Πολυπλοκότητα}

Τέλος, αναφορικά με την πολυπλοκότητα, αναφέρεται πως ο ορισμός της έννοιας της πολυπλοκότητας προσεγγίζεται δύσκολα. Ήδη από τη αναπαράσταση ενός γραμμικού μπλοκ κώδικα, φαίνεται πως η πολυπλοκότητα περιγραφής (το ποσό μνήμης που χρειάζεται για να αποθηκευτεί ενάς κώδικας), είναι το πολύ $\min\langle Rn^2, \left(1-R\right)n^2\rangle$ \en{bits}, όπου $R$ ο ρυθμός του κώδικα. Επίσης όπως αναφέρθηκε ήδη, η κωδικοποίηση όπως προκύπτει από την εξίσωση \ref{eq:check equation}, γίνεται σε τετραγωνικό χρόνο $\mathcal{O}(n^2)$ \cite{richardson2008modern}.

Η πολυπλοκότητα αποκωδικοποίησης \en{MLD} σε ένα κανάλι \en{BSC} έχει αναλυθεί από τον \en{Berlekamp} κ.α. \cite{berlekamp1978inherent}. Αποδεικνύεται πως η \en{MLD} αποκωδικοποίηση είναι \en{NP-complete}, συνεπώς θεωρείται απίθανο να βρεθεί γενικός αλγόριθμος για τέτοιου τύπου αποκωδικοποίηση με πολυωνυμική πολυπλοκότητα \cite{bruck1990hardness}.
